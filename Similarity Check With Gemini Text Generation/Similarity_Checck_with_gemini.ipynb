{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import difflib\n",
    "import json\n",
    "\n",
    "# API call function\n",
    "\n",
    "def api_call_to_gemini(question):\n",
    "    api_url = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent\"\n",
    "    \n",
    "    API_KEY = \"AIzaSyAWrSA4pMISYR-dhYDHC8c6EWPjvxwBxvw\"\n",
    "    \n",
    "    prompt = f\"Answer the following question correctly without any unnecessary text. Only return the direct answer: {question}\"\n",
    "    \n",
    "    payload = {\n",
    "        \"contents\": [\n",
    "            {\"role\": \"user\", \"parts\": [{\"text\": prompt}]}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{api_url}?key={API_KEY}\", json=payload, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}, {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"API call failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Clean text function\n",
    "def clean_text(text):\n",
    "    return text.lower().strip().replace(\".\", \"\").replace(\",\", \"\")\n",
    "\n",
    "# Similarity calculation\n",
    "def calculate_similarity(answer1, answer2):\n",
    "    answer1 = clean_text(answer1)\n",
    "    answer2 = clean_text(answer2)\n",
    "    \n",
    "    if answer1 == answer2:\n",
    "        return 1.0\n",
    "    \n",
    "    if answer1 in answer2 or answer2 in answer1:\n",
    "        return 0.9  # High similarity for partial match\n",
    "    \n",
    "    return difflib.SequenceMatcher(None, answer1, answer2).ratio()\n",
    "\n",
    "# Store conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Check similarity and update conversation history\n",
    "def check_similarity(question, expected_answer):\n",
    "    response = api_call_to_gemini(question)\n",
    "    \n",
    "    if response:\n",
    "        generated_text = response.get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\", \"\").strip()\n",
    "        similarity_score = calculate_similarity(generated_text, expected_answer)\n",
    "        \n",
    "        print(f\"Generated Answer: {generated_text}\")\n",
    "        print(f\"Similarity Score: {similarity_score}\")\n",
    "        \n",
    "        save_accuracy(similarity_score)\n",
    "        \n",
    "        conversation_history.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": generated_text,\n",
    "            \"similarity_score\": similarity_score\n",
    "        })\n",
    "        \n",
    "        SIMILARITY_THRESHOLD = 0.8  \n",
    "        \n",
    "        if similarity_score >= SIMILARITY_THRESHOLD:\n",
    "            new_question = generate_next_question(question)\n",
    "            print(f\"‚úÖ Generated Next Question: {new_question}\")\n",
    "            conversation_history.append({\"generated_next_question\": new_question})\n",
    "        else:\n",
    "            refine_question(question, expected_answer)\n",
    "        \n",
    "        save_conversation()\n",
    "    else:\n",
    "        print(\"‚ùå Failed to get a valid response from the API.\")\n",
    "\n",
    "# Save similarity score\n",
    "def save_accuracy(similarity_score):\n",
    "    try:\n",
    "        with open(\"similarity_scores.txt\", \"a\") as file:\n",
    "            file.write(f\"Similarity Score: {similarity_score}\\n\")\n",
    "        print(f\"‚úÖ Similarity score {similarity_score} saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to save similarity score: {str(e)}\")\n",
    "\n",
    "# Generate refined question if similarity is low\n",
    "def refine_question(question, expected_answer):\n",
    "    print(\"üîÑ Generating a refined question...\")\n",
    "    \n",
    "    prompt = f\"The given answer does not match the expected question. Suggest a better question for this answer: {expected_answer}\"\n",
    "    response = api_call_to_gemini(prompt)\n",
    "    \n",
    "    if response:\n",
    "        refined_question = response.get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\", \"\").strip()\n",
    "        print(f\"üîπ Suggested New Question: {refined_question}\")\n",
    "        conversation_history.append({\"refined_question\": refined_question})\n",
    "    else:\n",
    "        print(\"‚ùå Failed to generate a refined question.\")\n",
    "\n",
    "# Generate next question if similarity is good\n",
    "def generate_next_question(previous_question):\n",
    "    prompt = f\"Generate a new question that is related to this previous question: {previous_question}\"\n",
    "    response = api_call_to_gemini(prompt)\n",
    "    \n",
    "    if response:\n",
    "        return response.get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\", \"\").strip()\n",
    "    return \"No new question generated.\"\n",
    "\n",
    "# Save conversation history\n",
    "def save_conversation():\n",
    "    try:\n",
    "        with open(\"conversation_history.json\", \"w\") as file:\n",
    "            json.dump(conversation_history, file, indent=4)\n",
    "        print(\"‚úÖ Conversation history saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to save conversation history: {str(e)}\")\n",
    "\n",
    "# Example input\n",
    "question = \"What should I do when faced with a tight deadline?\"\n",
    "expected_answer = \"now i am felling sleepy.\"\n",
    "\n",
    "# Check similarity and loop through conversation\n",
    "check_similarity(question, expected_answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
